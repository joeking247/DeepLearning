{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the CIFAR-10\n",
    "def load_CIFAR10(pos, n_chunks=1):\n",
    "    Xtr = []\n",
    "    Ytr = []\n",
    "    for i in range(n_chunks):\n",
    "        train = unpickle(pos + '/data_batch_{0}'.format(i + 1))\n",
    "        Xtr.extend(train[b'data'])\n",
    "        Ytr.extend(train[b'labels'])\n",
    "        test = unpickle(pos + '/test_batch')\n",
    "        Xte = test[b'data']\n",
    "        Yte = test[b'labels']\n",
    "    return np.array(Xtr), np.array(Ytr), np.array(Xte), np.array(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (Ytr, Yte):\n",
    "    Ytr_onehot = np.zeros((Ytr.size, 10))\n",
    "    Yte_onehot = np.zeros((Yte.size, 10))\n",
    "    for i in range(Ytr.size):\n",
    "        Ytr_onehot[i][Ytr[i]] = 1\n",
    "    for i in range(Yte.size):\n",
    "        Yte_onehot[i][Yte[i]] = 1\n",
    "    return Ytr_onehot, Yte_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "Xtr, Ytr, Xte, Yte = load_CIFAR10('cifar-10-batches-py', 5)\n",
    "                                 \n",
    "# image data, each data size is 32*32*3\n",
    "Xtr = Xtr.reshape(50000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "Xte= Xte.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
    "\n",
    "# label data of train and test data, label data is represented by one-hot encoding\n",
    "Ytr_onehot, Yte_onehot = onehot_encoding(Ytr, Yte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "dropout_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epsilon = 1e-3\n",
    "### Implement the layers of CNNs \n",
    "W1 = tf.Variable(tf.random_normal([3,3,3,32], stddev=0.01))\n",
    "# padding = 'SAME' keeps output size equal to input.\n",
    "\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "# Pooling layer\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_mean1, batch_var1 = tf.nn.moments(L1,[0])\n",
    "scale1 = tf.Variable(tf.ones([32, 32, 32]))\n",
    "beta1 = tf.Variable(tf.zeros([32, 32, 32]))\n",
    "BN1 = tf.nn.batch_normalization(L1,batch_mean1,batch_var1,beta1,scale1,epsilon)\n",
    "L1 = tf.nn.relu(BN1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "batch_mean2, batch_var2 = tf.nn.moments(L2,[0])\n",
    "scale2 = tf.Variable(tf.ones([16, 16, 64]))\n",
    "beta2 = tf.Variable(tf.zeros([16, 16, 64]))\n",
    "BN2 = tf.nn.batch_normalization(L2,batch_mean2,batch_var2,beta2,scale2,epsilon)\n",
    "L2 = tf.nn.relu(BN2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([8*8*64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 8*8*64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "# dropout\n",
    "L3 = tf.nn.dropout(L3, dropout_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cost function, you can change the implementation\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement the train process ###\n",
    "batch_size = 100\n",
    "total_batch = int(50000 / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implement the test process ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  1.722\n",
      "Accuracy 0.5165\n",
      "Epoch: 0002 Avg. cost =  1.355\n",
      "Accuracy 0.5926\n",
      "Epoch: 0003 Avg. cost =  1.203\n",
      "Accuracy 0.6249\n",
      "Epoch: 0004 Avg. cost =  1.106\n",
      "Accuracy 0.6554\n",
      "Epoch: 0005 Avg. cost =  1.033\n",
      "Accuracy 0.6747\n",
      "Epoch: 0006 Avg. cost =  0.982\n",
      "Accuracy 0.6857\n",
      "Epoch: 0007 Avg. cost =  0.943\n",
      "Accuracy 0.6952\n",
      "Epoch: 0008 Avg. cost =  0.909\n",
      "Accuracy 0.7086\n",
      "Epoch: 0009 Avg. cost =  0.877\n",
      "Accuracy 0.7114\n",
      "Epoch: 0010 Avg. cost =  0.853\n",
      "Accuracy 0.7159\n"
     ]
    }
   ],
   "source": [
    "#~10\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Xtr[batch_size*i:batch_size*(i+1)]\n",
    "        batch_ys = Ytr_onehot[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          dropout_prob: 0.4})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch +1),\n",
    "         'Avg. cost = ', '{:,.3f}'.format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, \n",
    "                               feed_dict={\n",
    "                                   X: Xte,\n",
    "                                   Y: Yte_onehot,\n",
    "                                   dropout_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  0.825\n",
      "Accuracy 0.7204\n",
      "Epoch: 0002 Avg. cost =  0.800\n",
      "Accuracy 0.7302\n",
      "Epoch: 0003 Avg. cost =  0.775\n",
      "Accuracy 0.7307\n",
      "Epoch: 0004 Avg. cost =  0.762\n",
      "Accuracy 0.732\n",
      "Epoch: 0005 Avg. cost =  0.738\n",
      "Accuracy 0.738\n",
      "Epoch: 0006 Avg. cost =  0.720\n",
      "Accuracy 0.7365\n",
      "Epoch: 0007 Avg. cost =  0.700\n",
      "Accuracy 0.7393\n",
      "Epoch: 0008 Avg. cost =  0.683\n",
      "Accuracy 0.7414\n",
      "Epoch: 0009 Avg. cost =  0.668\n",
      "Accuracy 0.7464\n",
      "Epoch: 0010 Avg. cost =  0.652\n",
      "Accuracy 0.7476\n"
     ]
    }
   ],
   "source": [
    "#~20\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Xtr[batch_size*i:batch_size*(i+1)]\n",
    "        batch_ys = Ytr_onehot[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          dropout_prob: 0.4})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch +1),\n",
    "         'Avg. cost = ', '{:,.3f}'.format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, \n",
    "                               feed_dict={\n",
    "                                   X: Xte,\n",
    "                                   Y: Yte_onehot,\n",
    "                                   dropout_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  0.632\n",
      "Accuracy 0.7494\n",
      "Epoch: 0002 Avg. cost =  0.619\n",
      "Accuracy 0.7505\n",
      "Epoch: 0003 Avg. cost =  0.605\n",
      "Accuracy 0.7514\n",
      "Epoch: 0004 Avg. cost =  0.592\n",
      "Accuracy 0.7526\n",
      "Epoch: 0005 Avg. cost =  0.582\n",
      "Accuracy 0.7552\n",
      "Epoch: 0006 Avg. cost =  0.565\n",
      "Accuracy 0.7509\n",
      "Epoch: 0007 Avg. cost =  0.551\n",
      "Accuracy 0.7538\n",
      "Epoch: 0008 Avg. cost =  0.537\n",
      "Accuracy 0.7591\n",
      "Epoch: 0009 Avg. cost =  0.521\n",
      "Accuracy 0.7596\n",
      "Epoch: 0010 Avg. cost =  0.514\n",
      "Accuracy 0.7579\n"
     ]
    }
   ],
   "source": [
    "#~30\n",
    "for epoch in range(10):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Xtr[batch_size*i:batch_size*(i+1)]\n",
    "        batch_ys = Ytr_onehot[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          dropout_prob: 0.4})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch +1),\n",
    "         'Avg. cost = ', '{:,.3f}'.format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, \n",
    "                               feed_dict={\n",
    "                                   X: Xte,\n",
    "                                   Y: Yte_onehot,\n",
    "                                   dropout_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  0.498\n",
      "Accuracy 0.7633\n",
      "Epoch: 0002 Avg. cost =  0.490\n",
      "Accuracy 0.7626\n",
      "Epoch: 0003 Avg. cost =  0.475\n",
      "Accuracy 0.7627\n",
      "Epoch: 0004 Avg. cost =  0.468\n",
      "Accuracy 0.7617\n",
      "Epoch: 0005 Avg. cost =  0.455\n",
      "Accuracy 0.759\n"
     ]
    }
   ],
   "source": [
    "#~35\n",
    "for epoch in range(5):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Xtr[batch_size*i:batch_size*(i+1)]\n",
    "        batch_ys = Ytr_onehot[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          dropout_prob: 0.4})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch +1),\n",
    "         'Avg. cost = ', '{:,.3f}'.format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, \n",
    "                               feed_dict={\n",
    "                                   X: Xte,\n",
    "                                   Y: Yte_onehot,\n",
    "                                   dropout_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 Avg. cost =  0.447\n",
      "Accuracy 0.7633\n",
      "Epoch: 0002 Avg. cost =  0.435\n",
      "Accuracy 0.7666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-14a01bbe6453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                feed_dict={X: batch_xs,\n\u001b[1;32m     10\u001b[0m                                           \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                           dropout_prob: 0.4})\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/snu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    total_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs = Xtr[batch_size*i:batch_size*(i+1)]\n",
    "        batch_ys = Ytr_onehot[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          dropout_prob: 0.4})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch +1),\n",
    "         'Avg. cost = ', '{:,.3f}'.format(total_cost/total_batch))\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "    print('Accuracy', sess.run(accuracy, \n",
    "                               feed_dict={\n",
    "                                   X: Xte,\n",
    "                                   Y: Yte_onehot,\n",
    "                                   dropout_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
